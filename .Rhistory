train.x <- lapply(sapply(train.customers,train.x.lists),as.character)
train.y <- lapply(sapply(train.customers,train.y.lists),as.character)
test.x <- lapply(sapply(test.customers,test.x.lists),as.character)
test.y <- lapply(sapply(test.customers,test.y.lists),as.character)
#Initializing an empty data frame to be filled in by loop
sim.df <- data.frame(test_customer=NULL,train_customer=NULL,similarity=NULL,shared_prods = NULL,num_prods=NULL)
num.prods <- unlist(lapply(train.x,function(x){return(length(unique(unlist(x))))}))
# Looping through each customer in the test set to find nearest neighbors.
# This takes my computer about 2 minutes to run.
for(i in 1:length(test.x)){
cust.name <- names(test.x)[i]
items.bought <- as.vector(unlist(test.x[i]))
num.items <- length(items.bought)
head(train.x)
# Only comparing customers that have same number of unique items (+ or - 1 item)
cust2.list <- train.x[which(num.prods > (0.8*num.items) & num.prods < (1.2*num.items))]
#cust2.list <- train.x[which(names(train.x) %in% same.region)]
cust2s <- names(cust2.list)
all.sims <- lapply(cust2.list,function(x){return(length(intersect(items.bought,as.vector(unlist(x)))))})
shared.prods <- as.vector(unlist(all.sims))
similarities <- as.vector(unlist(all.sims) / num.items)
try(new.rows <- data.frame(test_customer=cust.name,train_customer = cust2s, similarity=similarities,shared_prods=shared.prods,num_prods=num.items))
try(new.rows <- new.rows[order(new.rows$similarity,decreasing = TRUE),])
k <- 55 #only taking top k most similar machines. This number can be changed.
try(new.rows <- new.rows[c(1:k),])
try(row.names(new.rows) <-  NULL) #row names will be name of machines otherwise
try(sim.df <- rbind(sim.df,new.rows)) # adding the new rows to the initialized data frame
print(paste0("Finding Neighbors For Customer ",i," / ",length(test.x))) # just a progress tracker.
}
rm(list=ls())
t0 = proc.time()
routes <- read.csv(url("http://kddata.co/data/chapter6/routes.csv"),header=T)
prods <- read.csv(url("http://kddata.co/data/chapter6/products.csv"),header=T)
customers <- read.csv(url("http://kddata.co/data/chapter6/customers.csv"),header=T)
deets <- read.csv(url("http://kddata.co/data/chapter6/visitdetails.csv"),header=T)
visits <- read.csv(url("http://kddata.co/data/chapter6/visits.csv"),header=T)
##################
### Libraries  ###
##################
library(lubridate)
library(plyr)
library(sqldf)
library(AUC)
##################
### Formatting ###
##################
routes$RouteID <- as.character(routes$RouteID)
routes$WeekOrder <- as.character(routes$WeekOrder)
routes$WeekOrder <- as.factor(routes$WeekOrder)
prods$ProductID <- as.character(prods$ProductID)
customers$CustomerID <- as.character(customers$CustomerID)
customers$ZIP <- as.character(customers$ZIP)
deets$VisitDetailID <- as.character(deets$VisitDetailID)
deets$VisitDetailID <- as.character(deets$VisitDetailID)
deets$VisitID <- as.character(deets$VisitID)
visits$VisitID <- as.character(visits$VisitID)
visits$SalesRepresentativeID <- as.character(visits$SalesRepresentativeID)
visits$DateTime <- strptime(visits$VisitDate, "%d-%b-%y %H.%M.%S")
visits$VisitDate <- as.character(visits$VisitDate)
visits$VisitDate <- as.Date(visits$VisitDate,format="%d-%b-%y")
visits$year <- year(visits$DateTime)
visits$month <- month(visits$DateTime)
visits$mday <- day(visits$DateTime)
visits$hour <- hour(visits$DateTime)
customers$CustomerID <- as.character(customers$CustomerID)
####################################################################################
################
### Cleaning ###
################
prods <- prods[-which(prods$Family == ""),]
deets <- deets[which(deets$Quantity >= 0),]
prods <- prods[which(prods$Price >= 0),]
visits <- visits[which(visits$Amount >=0),]
head(deets)
####################
### Table Merges ###
####################
cust.routes <- merge(customers,routes,by="RouteID",all.x=TRUE)
cust.routes.visits <- merge(cust.routes,visits,by="CustomerID",all.x = TRUE)
deets.prods <- merge(deets,prods,by="ProductID")
base.table <- merge(cust.routes.visits,deets.prods,by="VisitID",all.x=TRUE)
################
# More Cleaning
################
sapply(base.table,function(x){length(which(is.na(x)))})
base.table <- base.table[-which(is.na(base.table$VisitID)),]
# These time periods are almost arbitrary. I fully expect them too be changed.
test.t4 <- max(base.table$VisitDate)
test.t3 <- test.t4 - 30
test.t2 <- test.t3-1
test.t1 <- test.t2 - 120
test.t2
test.t1
train.t4 <- test.t1
train.t3 <- train.t4- 30
train.t2 <- train.t3-1
train.t1 <- train.t2- 120
base.table <- base.table[-which(is.na(base.table$ProductID)),]
# Collecting all purchases that occurred in test independent period
test.prev.purchases <- base.table[which(base.table$VisitDate <= test.t2 &
base.table$VisitDate >= test.t1 &
base.table$Outcome == "SALES"),] ; head(test.prev.purchases)
# Collecting all purchases taht occurred in train independent period
train.prev.purchases <- base.table[which(base.table$VisitDate <= train.t2 &
base.table$VisitDate >= train.t1 &
base.table$Outcome == "SALES"),] ; head(train.prev.purchases)
# Names of Customers that made purchases before t2
test.customers <- unique(test.prev.purchases$CustomerID)
train.customers <- unique(train.prev.purchases$CustomerID)
# Collecting all purchase information that occurred in dependent period.
test.post.purchases <- base.table[which(base.table$VisitDate >= test.t3 &
base.table$VisitDate <= test.t4 &
base.table$CustomerID %in% test.customers &
base.table$Outcome == "SALES"),]
train.post.purchases <- base.table[which(base.table$VisitDate >= train.t3 &
base.table$VisitDate <= train.t4 &
base.table$CustomerID %in% train.customers &
base.table$Outcome == "SALES"),]
dim(test.prev.purchases)
dim(test.post.purchases)
dim(train.prev.purchases)
dim(train.post.purchases)
# Writing functions to build lists of products for independent and dependent periods for customers
train.x.lists <- function(x){
return(unique(train.prev.purchases$ProductID[which(train.prev.purchases$CustomerID == x)]))
}
train.y.lists <- function(x){
return(unique(train.post.purchases$ProductID[which(train.post.purchases$CustomerID == x)]))
}
test.x.lists <- function(x){
return(unique(test.prev.purchases$ProductID[which(test.prev.purchases$CustomerID == x)]))
}
test.y.lists <- function(x){
return(unique(test.post.purchases$ProductID[which(test.post.purchases$CustomerID == x)]))
}
# Starting a timer for proxy KNN code
start <- proc.time()
# Deploying above functions
train.customers <- as.character(unique(train.prev.purchases$CustomerID))
test.customers <- as.character(unique(test.prev.purchases$CustomerID))
train.x <- lapply(sapply(train.customers,train.x.lists),as.character)
train.y <- lapply(sapply(train.customers,train.y.lists),as.character)
test.x <- lapply(sapply(test.customers,test.x.lists),as.character)
test.y <- lapply(sapply(test.customers,test.y.lists),as.character)
#Initializing an empty data frame to be filled in by loop
sim.df <- data.frame(test_customer=NULL,train_customer=NULL,similarity=NULL,shared_prods = NULL,num_prods=NULL)
num.prods <- unlist(lapply(train.x,function(x){return(length(unique(unlist(x))))}))
# Looping through each customer in the test set to find nearest neighbors.
# This takes my computer about 2 minutes to run.
for(i in 1:length(test.x)){
cust.name <- names(test.x)[i]
items.bought <- as.vector(unlist(test.x[i]))
num.items <- length(items.bought)
head(train.x)
# Only comparing customers that have same number of unique items (+ or - 1 item)
cust2.list <- train.x[which(num.prods > (0.8*num.items) & num.prods < (1.2*num.items))]
#cust2.list <- train.x[which(names(train.x) %in% same.region)]
cust2s <- names(cust2.list)
all.sims <- lapply(cust2.list,function(x){return(length(intersect(items.bought,as.vector(unlist(x)))))})
shared.prods <- as.vector(unlist(all.sims))
similarities <- as.vector(unlist(all.sims) / num.items)
try(new.rows <- data.frame(test_customer=cust.name,train_customer = cust2s, similarity=similarities,shared_prods=shared.prods,num_prods=num.items))
try(new.rows <- new.rows[order(new.rows$similarity,decreasing = TRUE),])
k <- 55 #only taking top k most similar machines. This number can be changed.
try(new.rows <- new.rows[c(1:k),])
try(row.names(new.rows) <-  NULL) #row names will be name of machines otherwise
try(sim.df <- rbind(sim.df,new.rows)) # adding the new rows to the initialized data frame
print(paste0("Finding Neighbors For Customer ",i," / ",length(test.x))) # just a progress tracker.
}
dim(sim.df)
head(sim.df)
hist(sim.df$similarity)
###### Now making predictions about what our test_customers will buy in dependent period
test.customers <- as.character(unique(sim.df$test_customer))
make.neighbor.list <- function(x){
return(sim.df$train_customer[which(sim.df$test_customer == x)])
}
neighbor.list <- sapply(test.customers,make.neighbor.list)
neighbor.list <- lapply(neighbor.list,as.character)
make.predictions <- function(x){ # to be applied to neighbor.list
neighbors <- unlist(x)
pos <- which(names(train.y) %in% neighbors)
train.y.product.list <- train.y[pos]
x <- table(unlist(train.y.product.list)) / length(neighbors)
x <- x[order(x,decreasing=TRUE)]
return(x)
}
# A list of every single customer,and likely products they will buy in dependent period.
# The proportions represent the (%) of (k) neighbors who purchased those products
all.predictions <- lapply(neighbor.list,make.predictions)
head(all.predictions)
proc.time()-start
proc.time() - t0
rm(list=ls())
t0 = proc.time()
routes <- read.csv(url("http://kddata.co/data/chapter6/routes.csv"),header=T)
prods <- read.csv(url("http://kddata.co/data/chapter6/products.csv"),header=T)
customers <- read.csv(url("http://kddata.co/data/chapter6/customers.csv"),header=T)
deets <- read.csv(url("http://kddata.co/data/chapter6/visitdetails.csv"),header=T)
visits <- read.csv(url("http://kddata.co/data/chapter6/visits.csv"),header=T)
##################
### Libraries  ###
##################
library(lubridate)
library(plyr)
library(sqldf)
library(AUC)
##################
### Formatting ###
##################
routes$RouteID <- as.character(routes$RouteID)
routes$WeekOrder <- as.character(routes$WeekOrder)
routes$WeekOrder <- as.factor(routes$WeekOrder)
prods$ProductID <- as.character(prods$ProductID)
customers$CustomerID <- as.character(customers$CustomerID)
customers$ZIP <- as.character(customers$ZIP)
deets$VisitDetailID <- as.character(deets$VisitDetailID)
deets$VisitDetailID <- as.character(deets$VisitDetailID)
deets$VisitID <- as.character(deets$VisitID)
visits$VisitID <- as.character(visits$VisitID)
visits$SalesRepresentativeID <- as.character(visits$SalesRepresentativeID)
visits$DateTime <- strptime(visits$VisitDate, "%d-%b-%y %H.%M.%S")
visits$VisitDate <- as.character(visits$VisitDate)
visits$VisitDate <- as.Date(visits$VisitDate,format="%d-%b-%y")
visits$year <- year(visits$DateTime)
visits$month <- month(visits$DateTime)
visits$mday <- day(visits$DateTime)
visits$hour <- hour(visits$DateTime)
customers$CustomerID <- as.character(customers$CustomerID)
####################################################################################
################
### Cleaning ###
################
prods <- prods[-which(prods$Family == ""),]
deets <- deets[which(deets$Quantity >= 0),]
prods <- prods[which(prods$Price >= 0),]
visits <- visits[which(visits$Amount >=0),]
head(deets)
####################
### Table Merges ###
####################
cust.routes <- merge(customers,routes,by="RouteID",all.x=TRUE)
cust.routes.visits <- merge(cust.routes,visits,by="CustomerID",all.x = TRUE)
deets.prods <- merge(deets,prods,by="ProductID")
base.table <- merge(cust.routes.visits,deets.prods,by="VisitID",all.x=TRUE)
################
# More Cleaning
################
sapply(base.table,function(x){length(which(is.na(x)))})
base.table <- base.table[-which(is.na(base.table$VisitID)),]
# These time periods are almost arbitrary. I fully expect them too be changed.
test.t4 <- max(base.table$VisitDate)
test.t3 <- test.t4 - 30
test.t2 <- test.t3-1
test.t1 <- test.t2 - 120
test.t2
test.t1
train.t4 <- test.t1
train.t3 <- train.t4- 30
train.t2 <- train.t3-1
train.t1 <- train.t2- 120
base.table <- base.table[-which(is.na(base.table$ProductID)),]
# Collecting all purchases that occurred in test independent period
test.prev.purchases <- base.table[which(base.table$VisitDate <= test.t2 &
base.table$VisitDate >= test.t1 &
base.table$Outcome == "SALES"),] ; head(test.prev.purchases)
# Collecting all purchases taht occurred in train independent period
train.prev.purchases <- base.table[which(base.table$VisitDate <= train.t2 &
base.table$VisitDate >= train.t1 &
base.table$Outcome == "SALES"),] ; head(train.prev.purchases)
# Names of Customers that made purchases before t2
test.customers <- unique(test.prev.purchases$CustomerID)
train.customers <- unique(train.prev.purchases$CustomerID)
# Collecting all purchase information that occurred in dependent period.
test.post.purchases <- base.table[which(base.table$VisitDate >= test.t3 &
base.table$VisitDate <= test.t4 &
base.table$CustomerID %in% test.customers &
base.table$Outcome == "SALES"),]
train.post.purchases <- base.table[which(base.table$VisitDate >= train.t3 &
base.table$VisitDate <= train.t4 &
base.table$CustomerID %in% train.customers &
base.table$Outcome == "SALES"),]
dim(test.prev.purchases)
dim(test.post.purchases)
dim(train.prev.purchases)
dim(train.post.purchases)
# Writing functions to build lists of products for independent and dependent periods for customers
train.x.lists <- function(x){
return(unique(train.prev.purchases$ProductID[which(train.prev.purchases$CustomerID == x)]))
}
train.y.lists <- function(x){
return(unique(train.post.purchases$ProductID[which(train.post.purchases$CustomerID == x)]))
}
test.x.lists <- function(x){
return(unique(test.prev.purchases$ProductID[which(test.prev.purchases$CustomerID == x)]))
}
test.y.lists <- function(x){
return(unique(test.post.purchases$ProductID[which(test.post.purchases$CustomerID == x)]))
}
# Starting a timer for proxy KNN code
start <- proc.time()
# Deploying above functions
train.customers <- as.character(unique(train.prev.purchases$CustomerID))
test.customers <- as.character(unique(test.prev.purchases$CustomerID))
train.x <- lapply(sapply(train.customers,train.x.lists),as.character)
train.y <- lapply(sapply(train.customers,train.y.lists),as.character)
test.x <- lapply(sapply(test.customers,test.x.lists),as.character)
test.y <- lapply(sapply(test.customers,test.y.lists),as.character)
#Initializing an empty data frame to be filled in by loop
sim.df <- data.frame(test_customer=NULL,train_customer=NULL,similarity=NULL,shared_prods = NULL,num_prods=NULL)
num.prods <- unlist(lapply(train.x,function(x){return(length(unique(unlist(x))))}))
# Looping through each customer in the test set to find nearest neighbors.
# This takes my computer about 2 minutes to run.
for(i in 1:length(test.x)){
cust.name <- names(test.x)[i]
items.bought <- as.vector(unlist(test.x[i]))
num.items <- length(items.bought)
head(train.x)
# Only comparing customers that have same number of unique items (+ or - 1 item)
cust2.list <- train.x[which(num.prods > (0.8*num.items) & num.prods < (1.2*num.items))]
#cust2.list <- train.x[which(names(train.x) %in% same.region)]
cust2s <- names(cust2.list)
all.sims <- lapply(cust2.list,function(x){return(length(intersect(items.bought,as.vector(unlist(x)))))})
shared.prods <- as.vector(unlist(all.sims))
similarities <- as.vector(unlist(all.sims) / num.items)
try(new.rows <- data.frame(test_customer=cust.name,train_customer = cust2s, similarity=similarities,shared_prods=shared.prods,num_prods=num.items))
try(new.rows <- new.rows[order(new.rows$similarity,decreasing = TRUE),])
k <- 35 #only taking top k most similar machines. This number can be changed.
try(new.rows <- new.rows[c(1:k),])
try(row.names(new.rows) <-  NULL) #row names will be name of machines otherwise
try(sim.df <- rbind(sim.df,new.rows)) # adding the new rows to the initialized data frame
print(paste0("Finding Neighbors For Customer ",i," / ",length(test.x))) # just a progress tracker.
}
dim(sim.df)
head(sim.df)
hist(sim.df$similarity)
###### Now making predictions about what our test_customers will buy in dependent period
test.customers <- as.character(unique(sim.df$test_customer))
make.neighbor.list <- function(x){
return(sim.df$train_customer[which(sim.df$test_customer == x)])
}
neighbor.list <- sapply(test.customers,make.neighbor.list)
neighbor.list <- lapply(neighbor.list,as.character)
make.predictions <- function(x){ # to be applied to neighbor.list
neighbors <- unlist(x)
pos <- which(names(train.y) %in% neighbors)
train.y.product.list <- train.y[pos]
x <- table(unlist(train.y.product.list)) / length(neighbors)
x <- x[order(x,decreasing=TRUE)]
return(x)
}
# A list of every single customer,and likely products they will buy in dependent period.
# The proportions represent the (%) of (k) neighbors who purchased those products
all.predictions <- lapply(neighbor.list,make.predictions)
head(all.predictions)
proc.time()-start
proc.time() - t0
prod = read.csv("/home/tapajit/Courses/fall 2016/bzan552/dunnhumby_The-Complete-Journey/dunnhumby - The Complete Journey CSV/product.csv")
prod.agg = ddply(prod, .(DEPARTMENT), summarise, tot.prod = length(PRODUCT_ID))
View(prod.agg)
summary(prod.agg)
deptofinterest = prod.agg[which(prod.agg$tot.prod>20),]$DEPARTMENT
deptofinterest = factor(prod.agg[which(prod.agg$tot.prod>20),]$DEPARTMENT)
deptofinterest
tr_data = read.csv("/home/tapajit/Courses/fall 2016/bzan552/dunnhumby_The-Complete-Journey/dunnhumby - The Complete Journey CSV/transaction_data.csv")
summary(tr_data)
tr_data = tr_data[which(tr_data$QUANTITY != 0 & tr_data$SALES_VALUE != 0),]
summary(tr_data)
tr_data.prod = merge(tr_data,prod)
base4 = tr_data.prod[which(tr_data.prod$DEPARTMENT == "FLORAL"),]
View(base4)
quant3 = ddply(base4, .(PRODUCT_ID), summarise, tot.quant = sum(QUANTITY),  midsale = median(SALES_VALUE/QUANTITY))
quant4 = ddply(base4, .(PRODUCT_ID), summarise, tot.quant = sum(QUANTITY),  midsale = median(SALES_VALUE/QUANTITY))
View(quant4)
library(arules)
library(plyr)
tr_data = read.csv("/home/tapajit/Courses/fall 2016/bzan552/dunnhumby_The-Complete-Journey/dunnhumby - The Complete Journey CSV/transaction_data.csv")
prod = read.csv("/home/tapajit/Courses/fall 2016/bzan552/dunnhumby_The-Complete-Journey/dunnhumby - The Complete Journey CSV/product.csv")
tr_data = tr_data[which(tr_data$QUANTITY != 0 & tr_data$SALES_VALUE != 0),]
tr_data.prod = merge(tr_data,prod)
###############
base1 = tr_data.prod[which(tr_data.prod$DEPARTMENT == "SEAFOOD" | tr_data.prod$DEPARTMENT =="SEAFOOD-PCKGD"),]
basket1=as(split(base1[,1], base1[,3]),"transactions")
quant1 = ddply(base1, .(PRODUCT_ID), summarise, tot.quant = sum(QUANTITY),  midsale = median(SALES_VALUE/QUANTITY))
k = quant1[which(quant1$tot.quant>quantile(quant1$tot.quant,0.75)),]
l = quant1[which(quant1$tot.quant<quantile(quant1$tot.quant,0.95)),]
sets <- eclat(basket1, parameter = list(supp = 0.001, minlen=2))
sets.sub = subset(sets, subset = items %in% as.character(k$PRODUCT_ID))
# frq = c()
# z = numeric(0)
#
# for( i in 1:length(sets.sub)){
#   f <- as.numeric(unlist(strsplit(LIST(sets.sub[i]@items)[[1]],split=" ")))
#   z = c(z,f)
#   if (sum(is.na(match(f,l$PRODUCT_ID)))>0) frq = c(frq,i)
# }
sets.final = subset(sets.sub, subset = items %in% as.character(l$PRODUCT_ID))
#########
base2 = tr_data.prod[which(tr_data.prod$DEPARTMENT == "PASTRY" | tr_data.prod$DEPARTMENT =="GRO BAKERY"),]
basket2=as(split(base2[,1], base2[,3]),"transactions")
quant2 = ddply(base2, .(PRODUCT_ID), summarise, tot.quant = sum(QUANTITY),  midsale = median(SALES_VALUE/QUANTITY))
k2 = quant2[which(quant2$tot.quant>quantile(quant2$tot.quant,0.75)),]
l2 = quant2[which(quant2$tot.quant<quantile(quant2$tot.quant,0.99)),]
sets2 <- eclat(basket2, parameter = list(supp = 0.001, minlen=2))
sets.sub.2 = subset(sets2, subset = items %in% as.character(k2$PRODUCT_ID))
# frq = c()
# z = numeric(0)
#
# for( i in 1:length(sets.sub)){
#   f <- as.numeric(unlist(strsplit(LIST(sets.sub[i]@items)[[1]],split=" ")))
#   z = c(z,f)
#   if (sum(is.na(match(f,l$PRODUCT_ID)))>0) frq = c(frq,i)
# }
sets.final.2 = subset(sets.sub.2, subset = items %in% as.character(l2$PRODUCT_ID))
# not useful
###############
base3 = tr_data.prod[which(tr_data.prod$DEPARTMENT == "DELI" | tr_data.prod$DEPARTMENT =="DAIRY DELI" | tr_data.prod$DEPARTMENT == "DELI/SNACK BAR"),]
basket3=as(split(base3[,1], base3[,3]),"transactions")
quant3 = ddply(base3, .(PRODUCT_ID), summarise, tot.quant = sum(QUANTITY),  midsale = median(SALES_VALUE/QUANTITY))
k3 = quant3[which(quant3$tot.quant>quantile(quant3$tot.quant,0.98)),]
l3 = quant3[which(quant3$tot.quant<quantile(quant3$tot.quant,0.98)),]
sets3 <- eclat(basket3, parameter = list(supp = 0.001, minlen=2))
(sets.sub.3 = subset(sets3, subset = items %in% as.character(k3$PRODUCT_ID)))
# frq = c()
# z = numeric(0)
#
# for( i in 1:length(sets.sub)){
#   f <- as.numeric(unlist(strsplit(LIST(sets.sub[i]@items)[[1]],split=" ")))
#   z = c(z,f)
#   if (sum(is.na(match(f,l$PRODUCT_ID)))>0) frq = c(frq,i)
# }
(sets.final.3 = subset(sets.sub.3, subset = items %in% as.character(l3$PRODUCT_ID)))
inspect(sets.final)
inspect(sets.final.2)
inspect(sets2)
inspect(sets.sub.2)
inspect(sets.final.3)
setwd("/home/tapajit/Courses/fall 2016/bzan552/hw13")
library(arules)
?read.transactions
coursetopic = read.transactions("Coursetopics.csv", format = "single", sep = ",", skip = 1)
coursetopic = read.csv("Coursetopics.csv")
coursetopic = transform(coursetopic, Intro=as.factor(Intro), DataMining=as.factor(DataMining),Survey=as.factor(Survey), Cat.Data=as.factor(Cat.Data), Regression=as.factor(Regression), Forecast=as.factor(Forecast), DOE=as.factor(DOE), SW=as.factor(SW))
courses = as(coursetopic, "transactions")
inspect(courses)
?apriori
rules = apriori(courses)
inspect(rules[1:6])
rules = apriori(courses, control = list(verbose=F),
parameter = list(minlen=2, supp=0.2))
rules
rules.sorted = sort(rules, by="confidence")
inspect(rules.sorted[1:3])
inspect(rules.sorted)
inspect(rules.sorted[1:3])
rules = apriori(courses, control = list(verbose=F),
parameter = list(minlen=2))
rules.sorted = sort(rules, by="confidence")
inspect(rules.sorted[1:3])
c(rep("hh", times=3))
cosmetic = read.csv("Cosmetics.csv", row.names = 1, colClasses = c(rep("factor", times=14)))
cosdata = as(cosmetic, "transactions")
inspect(cosdata)
(rules = apriori(cosdata, control = list(verbose=F),
parameter = list(minlen=2)))
(rules = apriori(cosdata, control = list(verbose=F),
parameter = list(minlen=2, supp=0.2)))
(rules = apriori(cosdata, control = list(verbose=F),
parameter = list(minlen=2, supp=0.3)))
rules.sorted = sort(rules, by="lift")
inspect(rules.sorted[1:3])
(rules = apriori(cosdata, control = list(verbose=F),
parameter = list(minlen=2, supp=0.2)))
rules.sorted = sort(rules, by="lift")
inspect(rules.sorted[1:3])
setwd("~/Work/release_qual/model")
#Reading .user data
filelist <- list.files(path = "../data/data1_May16/", pattern = "*4.new.user", full.names = TRUE)
#Reading New data
filelist1 <- list.files(path = "../data/data1_May16/", pattern = "*4.new$", full.names = TRUE)
UserFile = do.call(rbind, lapply(filelist, function(x) read.csv(file = x,sep=";",na.strings="(not set)")))
UserFile[,7] <- as.Date(UserFile[,7],"%Y%m%d")
UserFile[,8] <- as.integer(UserFile[,8])
UserFile[,9] <- as.integer(UserFile[,9])
UserFile[,10] <- as.numeric(UserFile[,10])
UserFile <- UserFile[order(UserFile[,7]),]
NewData <- do.call(rbind, lapply(filelist1, function(x) read.csv(file = x,sep=";")))
NewData[,3] <- as.Date(as.character(NewData[,3]),"%Y%m%d")
NewData <- NewData[order(NewData[,3]),]
total = merge(NewData,UserFile,all=T)
total = total[complete.cases(total),]
total$ga.deviceCategory <- factor(total$ga.deviceCategory)
total$ga.fatalExceptions <- NULL
total$ga.timeOnSite  <- NULL
total <- total[order(total[,3]),]
View(total)
library(lubridate)
df <- data.frame(
date = today() + days(1:300),
x = runif(300)
)
df$my <- floor_date(df$date, "month")
library(plyr)
ddply(df, "my", summarise, x = mean(x))
library(lubridate)
total$month = floor_date(total$ga.date,"month")
View(total)
?ddply
base = ddply(total, .(month, ga.appVersion, ga.operatingSystemVersion), summarise,
tot.excep = sum(ga.exceptions), tot.newvisits = sum(ga.newVisits),
tot.newusers = sum(ga.newUsers), tot.users = sum(ga.users), tot.sessionperuser = sum(ga.sessionsPerUser))
View(base)
